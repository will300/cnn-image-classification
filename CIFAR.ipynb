{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and Convolutional Neural Network for CIFAR Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a similar approach as MNIST.ipynb to classifying image data. However, more data pre-processing is needed to transform the raw file information into arrays with the right dimensions for use as input to the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells deal with pre-processing the data loaded from pickle files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict_1 = unpickle(\"data_batch_1.p\")\n",
    "train_dict_2 = unpickle(\"data_batch_2.p\")\n",
    "train_dict_3 = unpickle(\"data_batch_3.p\")\n",
    "train_dict_4 = unpickle(\"data_batch_4.p\")\n",
    "train_dict_5 = unpickle(\"data_batch_5.p\")\n",
    "\n",
    "class_labels_dict = unpickle(\"batches.meta.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n"
     ]
    }
   ],
   "source": [
    "print(class_labels_dict[b'label_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_dict):\n",
    "    image_data = data_dict[b'data']\n",
    "    img_ctr = 0\n",
    "    \n",
    "    for image in image_data:\n",
    "\n",
    "        red = np.reshape(image[:1024], (1,32,32,1))\n",
    "        green = np.reshape(image[1024:2048], (1,32,32,1))\n",
    "        blue = np.reshape(image[2048:3072], (1,32,32,1))\n",
    "        rg = np.append(red, green, axis=3)\n",
    "        rgb = np.append(rg, blue, axis=3)\n",
    "    \n",
    "        if img_ctr == 0:\n",
    "            dict_images = rgb\n",
    "        else:\n",
    "            dict_images = np.append(dict_images, rgb, axis=0)\n",
    "        \n",
    "        img_ctr += 1   \n",
    "        \n",
    "    return(dict_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_1 = process_data(train_dict_1)\n",
    "train_images_2 = process_data(train_dict_2)\n",
    "train_images = np.append(train_images_1, train_images_2, axis=0)\n",
    "train_images_3 = process_data(train_dict_3)\n",
    "train_images = np.append(train_images, train_images_3, axis=0)\n",
    "train_images_4 = process_data(train_dict_4)\n",
    "train_images = np.append(train_images, train_images_4, axis=0)\n",
    "train_images_5 = process_data(train_dict_5)\n",
    "train_images = np.append(train_images, train_images_5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_1 = train_dict_1[b'labels']\n",
    "train_labels_2 = train_dict_2[b'labels']\n",
    "train_labels = np.append(train_labels_1, train_labels_2, axis=0)\n",
    "train_labels_3 = train_dict_3[b'labels']\n",
    "train_labels = np.append(train_labels, train_labels_3, axis=0)\n",
    "train_labels_4 = train_dict_4[b'labels']\n",
    "train_labels = np.append(train_labels, train_labels_4, axis=0)\n",
    "train_labels_5 = train_dict_5[b'labels']\n",
    "train_labels = np.append(train_labels, train_labels_5, axis=0)\n",
    "train_classes = []\n",
    "\n",
    "for label in train_labels:    \n",
    "    class_ = class_labels_dict[b'label_names'][label]\n",
    "    train_classes.append(class_)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Class: b'ship'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_number = 42870\n",
    "\n",
    "plt.imshow(train_images[image_number])\n",
    "print('Image Class: {}'.format(train_classes[image_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/yes/envs/py3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels = train_labels.reshape(len(train_labels), 1)\n",
    "\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "\n",
    "    input_tensor = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "    output_labels = tf.placeholder(tf.float32, (None, 10))\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    return (input_tensor, output_labels, learning_rate, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_tensor, keep_prob, reuse=None):\n",
    "    \n",
    "    with tf.variable_scope('network', reuse=reuse):\n",
    "    \n",
    "        # Tensor size: 32x32\n",
    "        conv_1 = tf.layers.conv2d(input_tensor, 64, 3, 1, padding='same')\n",
    "        conv_1 = tf.nn.relu(conv_1)\n",
    "        \n",
    "        #print(conv_1.shape)\n",
    "        \n",
    "        # Tensor size: 32x32\n",
    "        max_pool_1 = tf.layers.max_pooling2d(conv_1, 2, 2, padding='SAME')\n",
    "        max_pool_1 = tf.layers.batch_normalization(max_pool_1, training=True)\n",
    "        \n",
    "        #print(max_pool_1.shape)\n",
    "    \n",
    "        # Tensor size: 16x16\n",
    "        conv_2 = tf.layers.conv2d(max_pool_1, 128, 3, 1, padding='same')\n",
    "        conv_2 = tf.nn.relu(conv_2)\n",
    "        \n",
    "        #print(conv_2.shape)\n",
    "        \n",
    "        # Tensor size: 16x16\n",
    "        max_pool_2 = tf.layers.max_pooling2d(conv_2, 2, 2, padding='SAME')\n",
    "        max_pool_2 = tf.layers.batch_normalization(max_pool_2, training=True)\n",
    "        \n",
    "        #print(max_pool_2.shape)\n",
    "    \n",
    "        # Tensor size: 8x8\n",
    "        conv_3 = tf.layers.conv2d(max_pool_2, 256, 3, 1, padding='same')\n",
    "        conv_3 = tf.nn.relu(conv_3)\n",
    "        \n",
    "        #print(conv_3.shape)\n",
    "        \n",
    "        # Tensor size: 8x8\n",
    "        max_pool_3 = tf.layers.max_pooling2d(conv_3, 2, 2, padding='SAME')\n",
    "        max_pool_3 = tf.layers.batch_normalization(max_pool_3, training=True)\n",
    "        \n",
    "        #print(max_pool_3.shape)\n",
    "    \n",
    "        # Tensor size: 4x4\n",
    "        conv_4 = tf.layers.conv2d(max_pool_3, 512, 3, 1, padding='same')\n",
    "        conv_4 = tf.nn.relu(conv_4)\n",
    "        \n",
    "        #print(conv_4.shape)\n",
    "        \n",
    "        # Tensor size: 4x4\n",
    "        max_pool_4 = tf.layers.max_pooling2d(conv_4, 2, 2, padding='SAME')\n",
    "        max_pool_4 = tf.layers.batch_normalization(max_pool_4, training=True)\n",
    "        \n",
    "        #print(max_pool_4.shape)\n",
    "    \n",
    "        # Tensor size: 2x2\n",
    "        flat_layer = tf.reshape(max_pool_4, (-1, 2*2*512))\n",
    "        \n",
    "        fc_layer_1 = tf.layers.dense(flat_layer, 128)\n",
    "        fc_layer_1 = tf.nn.dropout(fc_layer_1, keep_prob)\n",
    "        fc_layer_1 = tf.layers.batch_normalization(fc_layer_1, training=True)\n",
    "        \n",
    "        fc_layer_2 = tf.layers.dense(fc_layer_1, 256)\n",
    "        fc_layer_2 = tf.nn.dropout(fc_layer_2, keep_prob)\n",
    "        fc_layer_2 = tf.layers.batch_normalization(fc_layer_2, training=True)\n",
    "        \n",
    "        fc_layer_3 = tf.layers.dense(fc_layer_2, 512)\n",
    "        fc_layer_3 = tf.nn.dropout(fc_layer_3, keep_prob)\n",
    "        fc_layer_3 = tf.layers.batch_normalization(fc_layer_3, training=True)\n",
    "        \n",
    "        fc_layer_4 = tf.layers.dense(fc_layer_3, 1024)\n",
    "        fc_layer_4 = tf.nn.dropout(fc_layer_4, keep_prob)\n",
    "        fc_layer_4 = tf.layers.batch_normalization(fc_layer_4, training=True)\n",
    "        \n",
    "        fc_layer_5 = tf.layers.dense(fc_layer_4, batch_size)\n",
    "        fc_layer_5 = tf.nn.dropout(fc_layer_5, keep_prob)\n",
    "        fc_layer_5 = tf.layers.batch_normalization(fc_layer_5, training=True) \n",
    "        \n",
    "        output_layer = tf.layers.dense(flat_layer, 10)\n",
    "        logits = output_layer\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "    return logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss(logits, labels):\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate):\n",
    "    \n",
    "    train_vars = tf.trainable_variables()\n",
    "    params = [var for var in train_vars if var.name.startswith('network')]\n",
    "    \n",
    "    ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    upd = [op for op in ops if op.name.startswith('network')]\n",
    "    \n",
    "    with tf.control_dependencies(upd):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss=loss, var_list=params)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_features, input_labels, epoch_count, batch_size, learn_rate, keep_prob):\n",
    "    \n",
    "    input_tensor, output_labels, learning_rate, keeping_prob = build_inputs()\n",
    "    logits, output = build_cnn(input_tensor, keeping_prob)\n",
    "    loss = build_loss(logits, output_labels)\n",
    "    opt = build_optimizer(loss, learning_rate)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        steps = 0\n",
    "        \n",
    "        for current_epoch in range(epoch_count):\n",
    "            \n",
    "            for current_batch in range(int(len(input_features)/batch_size)):\n",
    "                \n",
    "                batch_images = input_features[current_batch * batch_size : current_batch * batch_size + batch_size, :, :, :]\n",
    "                batch_images = np.reshape(batch_images, (batch_size, 32, 32, 3))\n",
    "                batch_labels = input_labels[current_batch * batch_size : current_batch * batch_size + batch_size, :]\n",
    "                \n",
    "                steps += 1\n",
    "                \n",
    "                _ = sess.run(opt, feed_dict={input_tensor: batch_images, keeping_prob: keep_prob, output_labels: batch_labels, learning_rate: learn_rate})\n",
    "\n",
    "            \n",
    "                if steps % 10 == 0:\n",
    "                    current_loss = loss.eval({input_tensor: batch_images, output_labels: batch_labels})\n",
    "                    print(\"Current epoch: {}/{}\".format(current_epoch + 1, epoch_count))\n",
    "                    print(\"Current loss: {}\".format(current_loss))\n",
    "                    print(\"Images trained on: {}\".format(steps*batch_size))\n",
    "        \n",
    "        saver.save(sess, \"/tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 1/10\n",
      "Current loss: 0.2937808632850647\n",
      "Images trained on: 1280\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.25408440828323364\n",
      "Images trained on: 2560\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.21441049873828888\n",
      "Images trained on: 3840\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.23775234818458557\n",
      "Images trained on: 5120\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.20055341720581055\n",
      "Images trained on: 6400\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.21047277748584747\n",
      "Images trained on: 7680\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.20936676859855652\n",
      "Images trained on: 8960\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.22123965620994568\n",
      "Images trained on: 10240\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.18751713633537292\n",
      "Images trained on: 11520\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.19357310235500336\n",
      "Images trained on: 12800\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.177808940410614\n",
      "Images trained on: 14080\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.175287127494812\n",
      "Images trained on: 15360\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.18740907311439514\n",
      "Images trained on: 16640\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.17683176696300507\n",
      "Images trained on: 17920\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.17224463820457458\n",
      "Images trained on: 19200\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.16392001509666443\n",
      "Images trained on: 20480\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.16950327157974243\n",
      "Images trained on: 21760\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1681067943572998\n",
      "Images trained on: 23040\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.14619150757789612\n",
      "Images trained on: 24320\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.13323058187961578\n",
      "Images trained on: 25600\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.16336114704608917\n",
      "Images trained on: 26880\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1553470343351364\n",
      "Images trained on: 28160\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.13513441383838654\n",
      "Images trained on: 29440\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.15867511928081512\n",
      "Images trained on: 30720\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1510762721300125\n",
      "Images trained on: 32000\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.14857549965381622\n",
      "Images trained on: 33280\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.13824309408664703\n",
      "Images trained on: 34560\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.16214047372341156\n",
      "Images trained on: 35840\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.14917102456092834\n",
      "Images trained on: 37120\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.16387225687503815\n",
      "Images trained on: 38400\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1634805053472519\n",
      "Images trained on: 39680\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.15539079904556274\n",
      "Images trained on: 40960\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1456649750471115\n",
      "Images trained on: 42240\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.14021819829940796\n",
      "Images trained on: 43520\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.12293922901153564\n",
      "Images trained on: 44800\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.1296912431716919\n",
      "Images trained on: 46080\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.12442420423030853\n",
      "Images trained on: 47360\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.14331522583961487\n",
      "Images trained on: 48640\n",
      "Current epoch: 1/10\n",
      "Current loss: 0.11788003146648407\n",
      "Images trained on: 49920\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11329559981822968\n",
      "Images trained on: 51200\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10895983129739761\n",
      "Images trained on: 52480\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10409814119338989\n",
      "Images trained on: 53760\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.14155986905097961\n",
      "Images trained on: 55040\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10696134716272354\n",
      "Images trained on: 56320\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.13148191571235657\n",
      "Images trained on: 57600\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.13176849484443665\n",
      "Images trained on: 58880\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.12525804340839386\n",
      "Images trained on: 60160\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10827106237411499\n",
      "Images trained on: 61440\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.1312909871339798\n",
      "Images trained on: 62720\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11183135211467743\n",
      "Images trained on: 64000\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11252699047327042\n",
      "Images trained on: 65280\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.13837888836860657\n",
      "Images trained on: 66560\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10027172416448593\n",
      "Images trained on: 67840\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.1083751767873764\n",
      "Images trained on: 69120\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10917796939611435\n",
      "Images trained on: 70400\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10881213843822479\n",
      "Images trained on: 71680\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11489994823932648\n",
      "Images trained on: 72960\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09521608054637909\n",
      "Images trained on: 74240\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09732687473297119\n",
      "Images trained on: 75520\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11650371551513672\n",
      "Images trained on: 76800\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10008380562067032\n",
      "Images trained on: 78080\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09207423776388168\n",
      "Images trained on: 79360\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10267989337444305\n",
      "Images trained on: 80640\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10700831562280655\n",
      "Images trained on: 81920\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10414092242717743\n",
      "Images trained on: 83200\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09031224250793457\n",
      "Images trained on: 84480\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.11750149726867676\n",
      "Images trained on: 85760\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10080095380544662\n",
      "Images trained on: 87040\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.1103840321302414\n",
      "Images trained on: 88320\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10030367225408554\n",
      "Images trained on: 89600\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.10930590331554413\n",
      "Images trained on: 90880\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.08516702800989151\n",
      "Images trained on: 92160\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09295640885829926\n",
      "Images trained on: 93440\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.07972480356693268\n",
      "Images trained on: 94720\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.08832868188619614\n",
      "Images trained on: 96000\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.0817074328660965\n",
      "Images trained on: 97280\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.09651080518960953\n",
      "Images trained on: 98560\n",
      "Current epoch: 2/10\n",
      "Current loss: 0.07528240978717804\n",
      "Images trained on: 99840\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.08104150742292404\n",
      "Images trained on: 101120\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07327990233898163\n",
      "Images trained on: 102400\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07696408033370972\n",
      "Images trained on: 103680\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.10454337298870087\n",
      "Images trained on: 104960\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07553523778915405\n",
      "Images trained on: 106240\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.0854913666844368\n",
      "Images trained on: 107520\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.09038541465997696\n",
      "Images trained on: 108800\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.0875287726521492\n",
      "Images trained on: 110080\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07777285575866699\n",
      "Images trained on: 111360\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.09097082167863846\n",
      "Images trained on: 112640\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.08041141927242279\n",
      "Images trained on: 113920\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.08041153103113174\n",
      "Images trained on: 115200\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.0914105549454689\n",
      "Images trained on: 116480\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.059681523591279984\n",
      "Images trained on: 117760\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06813542544841766\n",
      "Images trained on: 119040\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07378118485212326\n",
      "Images trained on: 120320\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07057138532400131\n",
      "Images trained on: 121600\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.08534355461597443\n",
      "Images trained on: 122880\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06208643317222595\n",
      "Images trained on: 124160\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07146688550710678\n",
      "Images trained on: 125440\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.08266846835613251\n",
      "Images trained on: 126720\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06979653239250183\n",
      "Images trained on: 128000\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.0517369881272316\n",
      "Images trained on: 129280\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06955669075250626\n",
      "Images trained on: 130560\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.0713745504617691\n",
      "Images trained on: 131840\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07495139539241791\n",
      "Images trained on: 133120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 3/10\n",
      "Current loss: 0.06654638051986694\n",
      "Images trained on: 134400\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07850956171751022\n",
      "Images trained on: 135680\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07104931771755219\n",
      "Images trained on: 136960\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06980295479297638\n",
      "Images trained on: 138240\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06897921860218048\n",
      "Images trained on: 139520\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.07271788269281387\n",
      "Images trained on: 140800\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.055782027542591095\n",
      "Images trained on: 142080\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06563393771648407\n",
      "Images trained on: 143360\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.05430400371551514\n",
      "Images trained on: 144640\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06553923338651657\n",
      "Images trained on: 145920\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.055937718600034714\n",
      "Images trained on: 147200\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.06093357875943184\n",
      "Images trained on: 148480\n",
      "Current epoch: 3/10\n",
      "Current loss: 0.05436975508928299\n",
      "Images trained on: 149760\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05634265020489693\n",
      "Images trained on: 151040\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04239661991596222\n",
      "Images trained on: 152320\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04939369484782219\n",
      "Images trained on: 153600\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.075315460562706\n",
      "Images trained on: 154880\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05384698510169983\n",
      "Images trained on: 156160\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.053691696375608444\n",
      "Images trained on: 157440\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.06541019678115845\n",
      "Images trained on: 158720\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05116994306445122\n",
      "Images trained on: 160000\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04792334511876106\n",
      "Images trained on: 161280\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.056842852383852005\n",
      "Images trained on: 162560\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.06072644516825676\n",
      "Images trained on: 163840\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05198625847697258\n",
      "Images trained on: 165120\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05915149301290512\n",
      "Images trained on: 166400\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04119367152452469\n",
      "Images trained on: 167680\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04539438337087631\n",
      "Images trained on: 168960\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04696039855480194\n",
      "Images trained on: 170240\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.044625937938690186\n",
      "Images trained on: 171520\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.051980502903461456\n",
      "Images trained on: 172800\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04154716432094574\n",
      "Images trained on: 174080\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.051360536366701126\n",
      "Images trained on: 175360\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.05549079179763794\n",
      "Images trained on: 176640\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.038701098412275314\n",
      "Images trained on: 177920\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.03298266977071762\n",
      "Images trained on: 179200\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04756370186805725\n",
      "Images trained on: 180480\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04570584371685982\n",
      "Images trained on: 181760\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.0448068343102932\n",
      "Images trained on: 183040\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04571778327226639\n",
      "Images trained on: 184320\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.050020791590213776\n",
      "Images trained on: 185600\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04420336335897446\n",
      "Images trained on: 186880\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.046565648168325424\n",
      "Images trained on: 188160\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04660389572381973\n",
      "Images trained on: 189440\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04705843701958656\n",
      "Images trained on: 190720\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.03312814235687256\n",
      "Images trained on: 192000\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.04199517145752907\n",
      "Images trained on: 193280\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.03734039142727852\n",
      "Images trained on: 194560\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.035073310136795044\n",
      "Images trained on: 195840\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.036816179752349854\n",
      "Images trained on: 197120\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.031430136412382126\n",
      "Images trained on: 198400\n",
      "Current epoch: 4/10\n",
      "Current loss: 0.03528103977441788\n",
      "Images trained on: 199680\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03530891612172127\n",
      "Images trained on: 200960\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.027707654982805252\n",
      "Images trained on: 202240\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.029744569212198257\n",
      "Images trained on: 203520\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03713664412498474\n",
      "Images trained on: 204800\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.030582953244447708\n",
      "Images trained on: 206080\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03721487522125244\n",
      "Images trained on: 207360\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03510161489248276\n",
      "Images trained on: 208640\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03321231156587601\n",
      "Images trained on: 209920\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02741878665983677\n",
      "Images trained on: 211200\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02883300743997097\n",
      "Images trained on: 212480\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.034107256680727005\n",
      "Images trained on: 213760\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.0328417643904686\n",
      "Images trained on: 215040\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03971880301833153\n",
      "Images trained on: 216320\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.025233060121536255\n",
      "Images trained on: 217600\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03126925602555275\n",
      "Images trained on: 218880\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02976321056485176\n",
      "Images trained on: 220160\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02363436296582222\n",
      "Images trained on: 221440\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.026685675606131554\n",
      "Images trained on: 222720\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.026162898167967796\n",
      "Images trained on: 224000\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.031050708144903183\n",
      "Images trained on: 225280\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.030196715146303177\n",
      "Images trained on: 226560\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.023689428344368935\n",
      "Images trained on: 227840\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.0250244177877903\n",
      "Images trained on: 229120\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02703344263136387\n",
      "Images trained on: 230400\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.021428536623716354\n",
      "Images trained on: 231680\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.03036884032189846\n",
      "Images trained on: 232960\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.026881342753767967\n",
      "Images trained on: 234240\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.026956569403409958\n",
      "Images trained on: 235520\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.027458559721708298\n",
      "Images trained on: 236800\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.029379669576883316\n",
      "Images trained on: 238080\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.027315115556120872\n",
      "Images trained on: 239360\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.0310833640396595\n",
      "Images trained on: 240640\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.028868338093161583\n",
      "Images trained on: 241920\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.0296006016433239\n",
      "Images trained on: 243200\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.02027815952897072\n",
      "Images trained on: 244480\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.022772694006562233\n",
      "Images trained on: 245760\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.023083141073584557\n",
      "Images trained on: 247040\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.020092934370040894\n",
      "Images trained on: 248320\n",
      "Current epoch: 5/10\n",
      "Current loss: 0.017380639910697937\n",
      "Images trained on: 249600\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.02208249270915985\n",
      "Images trained on: 250880\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.014227223582565784\n",
      "Images trained on: 252160\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.016628708690404892\n",
      "Images trained on: 253440\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.022440211847424507\n",
      "Images trained on: 254720\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.017535284161567688\n",
      "Images trained on: 256000\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.020997263491153717\n",
      "Images trained on: 257280\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.01953313872218132\n",
      "Images trained on: 258560\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.01779792085289955\n",
      "Images trained on: 259840\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.01835455372929573\n",
      "Images trained on: 261120\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.012694170698523521\n",
      "Images trained on: 262400\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.01985887996852398\n",
      "Images trained on: 263680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 6/10\n",
      "Current loss: 0.02559802494943142\n",
      "Images trained on: 264960\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.027926217764616013\n",
      "Images trained on: 266240\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.015059980563819408\n",
      "Images trained on: 267520\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.01824038289487362\n",
      "Images trained on: 268800\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.016683902591466904\n",
      "Images trained on: 270080\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.013937095180153847\n",
      "Images trained on: 271360\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.015051973052322865\n",
      "Images trained on: 272640\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.012577367015182972\n",
      "Images trained on: 273920\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.016567569226026535\n",
      "Images trained on: 275200\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.0207448061555624\n",
      "Images trained on: 276480\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.012096288613975048\n",
      "Images trained on: 277760\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.015454155392944813\n",
      "Images trained on: 279040\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.013304290361702442\n",
      "Images trained on: 280320\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.017726214602589607\n",
      "Images trained on: 281600\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.014692422933876514\n",
      "Images trained on: 282880\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.013094735331833363\n",
      "Images trained on: 284160\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.012777772732079029\n",
      "Images trained on: 285440\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.014932302758097649\n",
      "Images trained on: 286720\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.013556542806327343\n",
      "Images trained on: 288000\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.013316336087882519\n",
      "Images trained on: 289280\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.017681239172816277\n",
      "Images trained on: 290560\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.0160231776535511\n",
      "Images trained on: 291840\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.015531843528151512\n",
      "Images trained on: 293120\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.011277089826762676\n",
      "Images trained on: 294400\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.009529726579785347\n",
      "Images trained on: 295680\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.017091503366827965\n",
      "Images trained on: 296960\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.011836516670882702\n",
      "Images trained on: 298240\n",
      "Current epoch: 6/10\n",
      "Current loss: 0.011394303292036057\n",
      "Images trained on: 299520\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010914047248661518\n",
      "Images trained on: 300800\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.011107330210506916\n",
      "Images trained on: 302080\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010861480608582497\n",
      "Images trained on: 303360\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.011692809872329235\n",
      "Images trained on: 304640\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010146762244403362\n",
      "Images trained on: 305920\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.01178405899554491\n",
      "Images trained on: 307200\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.011412592604756355\n",
      "Images trained on: 308480\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.011720286682248116\n",
      "Images trained on: 309760\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.01118357665836811\n",
      "Images trained on: 311040\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010072519071400166\n",
      "Images trained on: 312320\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010857941582798958\n",
      "Images trained on: 313600\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.013268375769257545\n",
      "Images trained on: 314880\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.02461891807615757\n",
      "Images trained on: 316160\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.008790405467152596\n",
      "Images trained on: 317440\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.010833756998181343\n",
      "Images trained on: 318720\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00934823788702488\n",
      "Images trained on: 320000\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007228064350783825\n",
      "Images trained on: 321280\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.009000478312373161\n",
      "Images trained on: 322560\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.012149840593338013\n",
      "Images trained on: 323840\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.006987395696341991\n",
      "Images trained on: 325120\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00971367210149765\n",
      "Images trained on: 326400\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00910544116050005\n",
      "Images trained on: 327680\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007743558846414089\n",
      "Images trained on: 328960\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.011245274916291237\n",
      "Images trained on: 330240\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.009253323078155518\n",
      "Images trained on: 331520\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.008452169597148895\n",
      "Images trained on: 332800\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.009116826578974724\n",
      "Images trained on: 334080\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007282973732799292\n",
      "Images trained on: 335360\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00763152539730072\n",
      "Images trained on: 336640\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.009718457236886024\n",
      "Images trained on: 337920\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00849424209445715\n",
      "Images trained on: 339200\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.01079355739057064\n",
      "Images trained on: 340480\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.00811079703271389\n",
      "Images trained on: 341760\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.0066231354139745235\n",
      "Images trained on: 343040\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.009947774931788445\n",
      "Images trained on: 344320\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.008477358147501945\n",
      "Images trained on: 345600\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007811673916876316\n",
      "Images trained on: 346880\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007265897002071142\n",
      "Images trained on: 348160\n",
      "Current epoch: 7/10\n",
      "Current loss: 0.007157790474593639\n",
      "Images trained on: 349440\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.006420505233108997\n",
      "Images trained on: 350720\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005745685659348965\n",
      "Images trained on: 352000\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.009271693415939808\n",
      "Images trained on: 353280\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0068969144485890865\n",
      "Images trained on: 354560\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0068686651065945625\n",
      "Images trained on: 355840\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.006163311656564474\n",
      "Images trained on: 357120\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004991129972040653\n",
      "Images trained on: 358400\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.006589233875274658\n",
      "Images trained on: 359680\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.00541343679651618\n",
      "Images trained on: 360960\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005359692964702845\n",
      "Images trained on: 362240\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.007701742462813854\n",
      "Images trained on: 363520\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0064044976606965065\n",
      "Images trained on: 364800\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.017182117328047752\n",
      "Images trained on: 366080\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005622237455099821\n",
      "Images trained on: 367360\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.007220837287604809\n",
      "Images trained on: 368640\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.006448835134506226\n",
      "Images trained on: 369920\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004786749370396137\n",
      "Images trained on: 371200\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005998801440000534\n",
      "Images trained on: 372480\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004961669445037842\n",
      "Images trained on: 373760\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0040477304719388485\n",
      "Images trained on: 375040\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0053782714530825615\n",
      "Images trained on: 376320\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004326448775827885\n",
      "Images trained on: 377600\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.00424520019441843\n",
      "Images trained on: 378880\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004922145511955023\n",
      "Images trained on: 380160\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004856129642575979\n",
      "Images trained on: 381440\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005779372528195381\n",
      "Images trained on: 382720\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.00571167329326272\n",
      "Images trained on: 384000\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0050944979302585125\n",
      "Images trained on: 385280\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.00466448999941349\n",
      "Images trained on: 386560\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.003956575877964497\n",
      "Images trained on: 387840\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005482231266796589\n",
      "Images trained on: 389120\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.0055491928942501545\n",
      "Images trained on: 390400\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004857046063989401\n",
      "Images trained on: 391680\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.005093555431813002\n",
      "Images trained on: 392960\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004368547350168228\n",
      "Images trained on: 394240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 8/10\n",
      "Current loss: 0.004291715566068888\n",
      "Images trained on: 395520\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.006366456858813763\n",
      "Images trained on: 396800\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004619611892849207\n",
      "Images trained on: 398080\n",
      "Current epoch: 8/10\n",
      "Current loss: 0.004093959461897612\n",
      "Images trained on: 399360\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004139966797083616\n",
      "Images trained on: 400640\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0032082684338092804\n",
      "Images trained on: 401920\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0038532980252057314\n",
      "Images trained on: 403200\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0043144626542925835\n",
      "Images trained on: 404480\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004191530868411064\n",
      "Images trained on: 405760\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.005218504462391138\n",
      "Images trained on: 407040\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0042914943769574165\n",
      "Images trained on: 408320\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.00410225847736001\n",
      "Images trained on: 409600\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0035681568551808596\n",
      "Images trained on: 410880\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0035040192306041718\n",
      "Images trained on: 412160\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004580317996442318\n",
      "Images trained on: 413440\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003194998949766159\n",
      "Images trained on: 414720\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.006386338733136654\n",
      "Images trained on: 416000\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.00334652210585773\n",
      "Images trained on: 417280\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004263422451913357\n",
      "Images trained on: 418560\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004179770592600107\n",
      "Images trained on: 419840\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003747661830857396\n",
      "Images trained on: 421120\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003001383040100336\n",
      "Images trained on: 422400\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.002871690085157752\n",
      "Images trained on: 423680\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003730855882167816\n",
      "Images trained on: 424960\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0038649060297757387\n",
      "Images trained on: 426240\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0027606592047959566\n",
      "Images trained on: 427520\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0028402749449014664\n",
      "Images trained on: 428800\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.004218600690364838\n",
      "Images trained on: 430080\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.002476385561749339\n",
      "Images trained on: 431360\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0035183392465114594\n",
      "Images trained on: 432640\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.002670142101123929\n",
      "Images trained on: 433920\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0026373318396508694\n",
      "Images trained on: 435200\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003915200009942055\n",
      "Images trained on: 436480\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0031475808937102556\n",
      "Images trained on: 437760\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0038684732280671597\n",
      "Images trained on: 439040\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.003554369555786252\n",
      "Images trained on: 440320\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.002586185932159424\n",
      "Images trained on: 441600\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0027014848310500383\n",
      "Images trained on: 442880\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.002873985795304179\n",
      "Images trained on: 444160\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0021106000058352947\n",
      "Images trained on: 445440\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0034571406431496143\n",
      "Images trained on: 446720\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0029284947086125612\n",
      "Images trained on: 448000\n",
      "Current epoch: 9/10\n",
      "Current loss: 0.0019526336109265685\n",
      "Images trained on: 449280\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0027543571777641773\n",
      "Images trained on: 450560\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0032728039659559727\n",
      "Images trained on: 451840\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002298580249771476\n",
      "Images trained on: 453120\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.004183935467153788\n",
      "Images trained on: 454400\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002999612595885992\n",
      "Images trained on: 455680\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0030453321523964405\n",
      "Images trained on: 456960\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002559919375926256\n",
      "Images trained on: 458240\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0018640771741047502\n",
      "Images trained on: 459520\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0020409421995282173\n",
      "Images trained on: 460800\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0027161473408341408\n",
      "Images trained on: 462080\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0025672377087175846\n",
      "Images trained on: 463360\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002327397232875228\n",
      "Images trained on: 464640\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0030895571690052748\n",
      "Images trained on: 465920\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.001957028405740857\n",
      "Images trained on: 467200\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002698321361094713\n",
      "Images trained on: 468480\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0031442109029740095\n",
      "Images trained on: 469760\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0019765696488320827\n",
      "Images trained on: 471040\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002534493338316679\n",
      "Images trained on: 472320\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.003066424746066332\n",
      "Images trained on: 473600\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0018946683267131448\n",
      "Images trained on: 474880\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0030957963317632675\n",
      "Images trained on: 476160\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.003594262059777975\n",
      "Images trained on: 477440\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.001740162493661046\n",
      "Images trained on: 478720\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002040314255282283\n",
      "Images trained on: 480000\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0024780784733593464\n",
      "Images trained on: 481280\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.003561242250725627\n",
      "Images trained on: 482560\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.001796599244698882\n",
      "Images trained on: 483840\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0023174353409558535\n",
      "Images trained on: 485120\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002988585038110614\n",
      "Images trained on: 486400\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0020328357350081205\n",
      "Images trained on: 487680\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0022631678730249405\n",
      "Images trained on: 488960\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0022701581474393606\n",
      "Images trained on: 490240\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0025213712360709906\n",
      "Images trained on: 491520\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.002110519912093878\n",
      "Images trained on: 492800\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0026299217715859413\n",
      "Images trained on: 494080\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0017376169562339783\n",
      "Images trained on: 495360\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0020191532094031572\n",
      "Images trained on: 496640\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0015862137079238892\n",
      "Images trained on: 497920\n",
      "Current epoch: 10/10\n",
      "Current loss: 0.0017404810059815645\n",
      "Images trained on: 499200\n"
     ]
    }
   ],
   "source": [
    "epoch_count = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.7\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "\n",
    "with train_graph.as_default():\n",
    "    train(train_images, train_labels_one_hot, epoch_count, batch_size, learning_rate, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(input_data):\n",
    "    \n",
    "    input_tensor, output_labels, learning_rate, keep_prob = build_inputs()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session(graph=train_graph) as sess:\n",
    "        \n",
    "        saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "        \n",
    "        logits, output = build_cnn(input_tensor, keep_prob, reuse=True)\n",
    "        test_image = np.reshape(input_data, (1, 32, 32, 3))\n",
    "        current_output = output.eval({input_tensor:test_image})\n",
    "        class_ = class_labels_dict[b'label_names'][np.argmax(current_output)]\n",
    "    \n",
    "        plt.imshow(input_data, cmap='gray')\n",
    "        print(\"Predicted Image Class: {}\".format(class_))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = unpickle(\"test_batch.p\")\n",
    "test_images = process_data(test_dict)\n",
    "test_labels = test_dict[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Predicted Image Class: b'frog'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enter an integer between 1 and 10000 corresponding to the image in the testing set to be classified\n",
    "integer = 6804\n",
    "\n",
    "\n",
    "data_point_index = integer - 1\n",
    "input_data = test_images[data_point_index]\n",
    "\n",
    "with train_graph.as_default():\n",
    "    classify(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(x_test, y_test):\n",
    "    \n",
    "    input_tensor, output_labels, learning_rate, keep_prob = build_inputs()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session(graph=train_graph) as sess:\n",
    "        \n",
    "        saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "        \n",
    "        logits, output = build_cnn(input_tensor, keep_prob, reuse=True)\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "        for test_image, test_label in zip(x_test, y_test):\n",
    "            input_data = np.reshape(test_image, (1, 32, 32, 3))\n",
    "            current_output = output.eval({input_tensor:input_data, keep_prob:1})\n",
    "            class_ = np.argmax(current_output)   \n",
    "            if class_ == test_label:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy = correct / len(x_test)\n",
    "        print(\"Model accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Model accuracy: 0.6028\n"
     ]
    }
   ],
   "source": [
    "# Find the accuracy of this particular model \n",
    "with train_graph.as_default():\n",
    "    model_accuracy(test_images, test_labels)"
   ]
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
